{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "Carga_Datos_Kaggle_Tweeter_YahooFinance.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "!pip install yfinance"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yfinance\n",
            "  Downloading yfinance-0.1.63.tar.gz (26 kB)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.19.5)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from yfinance) (2.23.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.9)\n",
            "Collecting lxml>=4.5.1\n",
            "  Downloading lxml-4.6.3-cp37-cp37m-manylinux2014_x86_64.whl (6.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.3 MB 39.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24->yfinance) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (3.0.4)\n",
            "Building wheels for collected packages: yfinance\n",
            "  Building wheel for yfinance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yfinance: filename=yfinance-0.1.63-py2.py3-none-any.whl size=23919 sha256=67e2327fb03665b9c9f4597c1d4a50e4a58cc96293b2c26a99f7419c37eda9ce\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/87/8b/7ec24486e001d3926537f5f7801f57a74d181be25b11157983\n",
            "Successfully built yfinance\n",
            "Installing collected packages: lxml, yfinance\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "Successfully installed lxml-4.6.3 yfinance-0.1.63\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJNtIihoW7hC",
        "outputId": "553546a4-3b62-43a9-c07c-a632a20fda0a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "import sqlalchemy\n",
        "import pandas as pd\n",
        "import yfinance as yf"
      ],
      "outputs": [],
      "metadata": {
        "id": "eCzGmQVzIjeC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "import tweepy\n",
        "import datetime\n",
        "import json"
      ],
      "outputs": [],
      "metadata": {
        "id": "_qL09v3sTmd5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#########################\n",
        "# conexión a MariaDB\n",
        "#########################\n",
        "%load_ext sql\n",
        "%sql mysql+pymysql://ney:Pala$@localhost:3306/Tweets_NASDAQ_test\n",
        "\n",
        "from sqlalchemy import create_engine\n",
        "engine=create_engine(\"mysql+pymysql://ney:Pala$@localhost:3306/Tweets_NASDAQ_test\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "w42ZTcbUS6PU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "####################################################################################################\n",
        "# Lectura de CSV para la información de los tweets y la de la asocciación compañia Tweet\n",
        "####################################################################################################\n",
        "#Company = pd.read_csv('/home/ney/Documents/Big Data UN/archivos_nasdaq_kaggle/archive/Company.csv',sep=',',header=0)\n",
        "Company_Tweet = pd.read_csv('/home/ney/Documents/Big Data UN/archivos_nasdaq_kaggle/archive/Company_Tweet.csv',sep=',',header=0)\n",
        "Tweet = pd.read_csv('/home/ney/Documents/Big Data UN/archivos_nasdaq_kaggle/archive/Tweet.csv',sep=',',header=0)\n",
        "##################################################\n",
        "# configurando campos fecha\n",
        "##################################################\n",
        "import datetime\n",
        "# pasar de timestamp (segundos desde el inicio de UNIX)\n",
        "Tweet['post_date']=pd.to_datetime(Tweet['post_date'],unit='s')\n",
        "Tweet['post_date']=pd.to_datetime(Tweet['post_date'])\n",
        "\n",
        "###########################################################################\n",
        "# Carga de tweets (CSV de NASDAQ descargado de Kaggle) a MariaDB\n",
        "###########################################################################\n",
        "for i in range(Tweet.shape[0]):\n",
        "    try:\n",
        "        Tweet.iloc[i:i+1,0:].to_sql('Tweet', engine, if_exists='append', index=False, chunksize=1000)\n",
        "    except:\n",
        "        pass #or any other action\n",
        "# Carga de asociaciones entre Tweets y Compañia (CSV de NASDAQ descargado de Kaggle) a MariaDB\n",
        "for i in range(Company_Tweet.shape[0]):\n",
        "    try:\n",
        "        Company_Tweet.iloc[i:i+1,0:].to_sql('Company_Tweet', engine, if_exists='append', index=False, chunksize=1000)\n",
        "    except:\n",
        "        pass #or any other action\n",
        "###########################################################################\n",
        "# Borrar columna con el numero de comentarios en MariaDB y la base de datos \n",
        "###########################################################################\n",
        "%sql ALTER TABLE Tweet DROP COLUMN comment_num;\n",
        "\n",
        "###########################################################################\n",
        "# Carga valores de acciones desde Yahoo Finance \n",
        "###########################################################################\n",
        "salida = []\n",
        "ticker = ['AAPL', 'AMZN', 'GOOG', 'GOOGL', 'MSFT', 'TSLA']\n",
        "# Set the start and end date\n",
        "start_date = '2010-01-01'\n",
        "end_date = '2021-08-01'\n",
        "\n",
        "for tick in ticker:\n",
        "    # Get the data\n",
        "    data = yf.download(tick, start_date, end_date)\n",
        "    data.reset_index(inplace=True)\n",
        "    data[['ticker_symbol']] = str(tick)\n",
        "    data = data[['ticker_symbol', 'Date', 'Close', 'Volume', 'Open', 'High', 'Low']]\n",
        "    data.columns = ['ticker_symbol', 'day_date', 'close_value', 'volume', 'open_value', 'high_value', 'low_value']\n",
        "    salida.append(data)\n",
        "\n",
        "df_values = pd.concat(salida)\n",
        "df_values = df_values.reset_index(drop=True)\n",
        "#df_values['day_date'] = pd.to_datetime(df_values['day_date']).strftime('%Y-%m-%d')\n",
        "\n",
        "####################################################################################################\n",
        "# Carga de datos de NASDAQ, extraídos de yahoo finance, convertidos a DataFrame a MariaDB\n",
        "####################################################################################################\n",
        "for i in range(df_values.shape[0]):\n",
        "    try:\n",
        "        df_values.iloc[i:i+1,0:].to_sql('Company_Values', engine, if_exists='append', index=False, chunksize=1000)\n",
        "    except:\n",
        "        pass #or any other action\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "uATiNBscXFRV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracción de datos desde Twitter mediante el uso de su API y el paquete Tweepy que nos permite hacer las solicitudes mediante el API de una manera mas eficiente. Los códigos de acceso no son correctos por cuestiones de privacidad. "
      ],
      "metadata": {
        "id": "ZsNtzL3STrmH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "# llaves que suministra twitter developer \n",
        "consumer_key = 'lPQmSKDFW78Hxn1MYuEEgAEWp'\n",
        "consumer_secret ='fk4y7lsDongFiPAupeXQnZfFcKbr7oaPniKo9e2E4cXgqO65Oo'\n",
        "access_token = '4494677061-glQISPeeTbQeviskjFynauLOo2nF7HoKB5yAWUr'\n",
        "access_token_secret = 'yaQJsNFRSgrGS7EWOuarVpsM1dNC4s8naEpiqKFprf7Rl'\n",
        "\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "\n",
        "api = tweepy.API(auth,\n",
        "                 wait_on_rate_limit=True, # evita que se pare la lectura y espere hasta tener cupo de solicitud,\n",
        "                 wait_on_rate_limit_notify=True)"
      ],
      "outputs": [],
      "metadata": {
        "id": "Vt64tj-yUBWM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "source": [
        "# Creación función solicitud que \n",
        "#recibe (nombre_compañia, ticker, numero_dias_desde_inicio_busqueda, numero_dias_hasta_fin_busqueda, \n",
        "#        numero de tweets que se quiera solicitar)\n",
        "# Retorna un diccionario('Tweet','Company_Tweet') donde cada elemento es un dataframe\n",
        "\n",
        "def solicitud(comp, tick, dias_desde, dias_hasta, numero):\n",
        "  output1 = []\n",
        "  # periodo de tiempo en el que se realizara la busqueda\n",
        "  today = datetime.date.today()\n",
        "  desde = today - datetime.timedelta(days=dias_desde)\n",
        "  hasta = today - datetime.timedelta(days=dias_hasta)\n",
        "  for user in tweepy.Cursor(api.search, q=str(comp) + \" since:\" + str(desde)+ \" until:\" + str(hasta),tweet_mode='extended',result_type='mix', lang='en').items(numero):\n",
        "\n",
        "    tweet_id = user._json['id']\n",
        "    writer = user._json['user']['screen_name']\n",
        "    post_date = user._json['created_at']    \n",
        "    body = user._json['full_text']\n",
        "    retweet_num = user._json['retweet_count']\n",
        "    like_num = user._json['favorite_count']\n",
        "    ticker_symbol = str(comp)\n",
        "\n",
        "    line = {'tweet_id' : tweet_id, 'writer' : writer, 'post_date' : post_date, 'body' : body, 'retweet_num' : retweet_num, 'like_num' : like_num, 'ticker_symbol' : ticker_symbol}\n",
        "    output1.append(line) \n",
        "\n",
        "  df_tweets_comp = pd.DataFrame(output1)\n",
        "  df_tweets_comp['post_date']=pd.to_datetime(df_tweets_comp['post_date'])\n",
        "\n",
        "  Company_Tweet = df_tweets_comp[['tweet_id', 'ticker_symbol']]\n",
        "  Company_Tweet['ticker_symbol'] = Company_Tweet['ticker_symbol'].replace(comp, tick)\n",
        "  Tweet = df_tweets_comp[['tweet_id', 'writer', 'post_date', 'body', 'retweet_num', 'like_num']]\n",
        "  return ({'Company_Tweet':Company_Tweet, 'Tweet':Tweet})"
      ],
      "outputs": [],
      "metadata": {
        "id": "1R8HBCFBUbCp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "source": [
        "# Ejemplo solicitud de 2000 Tweets (los mas recientes y populares) para los tweets del ultimo día para Google \n",
        "solicitud1=solicitud('Google','GOOG', 1, 0, 2000)\n",
        "Tweet=solicitud1['Tweet']\n",
        "Company_Tweet=solicitud1['Company_Tweet']\n",
        "# Carga de tweets en la base de datos 'Tweets_NASDAQ' en MariaDB\n",
        "for i in range(Tweet.shape[0]):\n",
        "    try:\n",
        "        Tweet.iloc[i:i+1,0:].to_sql('Tweet', engine, if_exists='append', index=False, chunksize=1000)\n",
        "    except:\n",
        "        pass #or any other action\n",
        "for i in range(Company_Tweet.shape[0]):\n",
        "    try:\n",
        "        Company_Tweet.iloc[i:i+1,0:].to_sql('Company_Tweet', engine, if_exists='append', index=False, chunksize=1000)\n",
        "    except:\n",
        "        pass #or any other action"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMljRGFkWdlu",
        "outputId": "925405e9-fab2-4b4b-ce48-251851c8a095"
      }
    }
  ]
}